ot@843e844d3dd8:/workspace# python3 extract_pth_info.py llmmodel/pytorch/tsel_finetuned.pth
üîç llmmodel/pytorch/tsel_finetuned.pth ÌååÏùº Î∂ÑÏÑù Ï§ë...
/workspace/extract_pth_info.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(pth_path, map_location="cpu")

============================================================
üì¶ CHECKPOINT Íµ¨Ï°∞ Î∂ÑÏÑù
============================================================
üìã ÏµúÏÉÅÏúÑ ÌÇ§Îì§: ['model_state_dict', 'config', 'tokenizer', 'model_info']

üîë ÌÇ§: model_state_dict
   ÌÉÄÏûÖ: <class 'collections.OrderedDict'>
   ÌïòÏúÑ ÌÇ§Îì§: ['model.shared.weight', 'model.encoder.embed_tokens.weight', 'model.encoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.0.self_attn.k_proj.bias', 'model.encoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.0.self_attn.q_proj.weight', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.encoder.layers.0.fc1.weight', 'model.encoder.layers.0.fc1.bias', 'model.encoder.layers.0.fc2.weight', 'model.encoder.layers.0.fc2.bias', 'model.encoder.layers.0.final_layer_norm.weight', 'model.encoder.layers.0.final_layer_norm.bias', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.k_proj.bias', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.1.fc1.weight', 'model.encoder.layers.1.fc1.bias', 'model.encoder.layers.1.fc2.weight', 'model.encoder.layers.1.fc2.bias', 'model.encoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.1.final_layer_norm.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.2.fc1.weight', 'model.encoder.layers.2.fc1.bias', 'model.encoder.layers.2.fc2.weight', 'model.encoder.layers.2.fc2.bias', 'model.encoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.2.final_layer_norm.bias', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.3.fc1.weight', 'model.encoder.layers.3.fc1.bias', 'model.encoder.layers.3.fc2.weight', 'model.encoder.layers.3.fc2.bias', 'model.encoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.3.final_layer_norm.bias', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.4.fc1.weight', 'model.encoder.layers.4.fc1.bias', 'model.encoder.layers.4.fc2.weight', 'model.encoder.layers.4.fc2.bias', 'model.encoder.layers.4.final_layer_norm.weight', 'model.encoder.layers.4.final_layer_norm.bias', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.encoder.layers.5.fc1.weight', 'model.encoder.layers.5.fc1.bias', 'model.encoder.layers.5.fc2.weight', 'model.encoder.layers.5.fc2.bias', 'model.encoder.layers.5.final_layer_norm.weight', 'model.encoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.6.self_attn.k_proj.bias', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.6.self_attn_layer_norm.weight', 'model.encoder.layers.6.self_attn_layer_norm.bias', 'model.encoder.layers.6.fc1.weight', 'model.encoder.layers.6.fc1.bias', 'model.encoder.layers.6.fc2.weight', 'model.encoder.layers.6.fc2.bias', 'model.encoder.layers.6.final_layer_norm.weight', 'model.encoder.layers.6.final_layer_norm.bias', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.k_proj.bias', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.7.self_attn_layer_norm.weight', 'model.encoder.layers.7.self_attn_layer_norm.bias', 'model.encoder.layers.7.fc1.weight', 'model.encoder.layers.7.fc1.bias', 'model.encoder.layers.7.fc2.weight', 'model.encoder.layers.7.fc2.bias', 'model.encoder.layers.7.final_layer_norm.weight', 'model.encoder.layers.7.final_layer_norm.bias', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.8.self_attn.k_proj.bias', 'model.encoder.layers.8.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn_layer_norm.weight', 'model.encoder.layers.8.self_attn_layer_norm.bias', 'model.encoder.layers.8.fc1.weight', 'model.encoder.layers.8.fc1.bias', 'model.encoder.layers.8.fc2.weight', 'model.encoder.layers.8.fc2.bias', 'model.encoder.layers.8.final_layer_norm.weight', 'model.encoder.layers.8.final_layer_norm.bias', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.encoder.layers.9.self_attn.k_proj.bias', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.9.self_attn_layer_norm.weight', 'model.encoder.layers.9.self_attn_layer_norm.bias', 'model.encoder.layers.9.fc1.weight', 'model.encoder.layers.9.fc1.bias', 'model.encoder.layers.9.fc2.weight', 'model.encoder.layers.9.fc2.bias', 'model.encoder.layers.9.final_layer_norm.weight', 'model.encoder.layers.9.final_layer_norm.bias', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.10.self_attn.k_proj.bias', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.10.self_attn_layer_norm.weight', 'model.encoder.layers.10.self_attn_layer_norm.bias', 'model.encoder.layers.10.fc1.weight', 'model.encoder.layers.10.fc1.bias', 'model.encoder.layers.10.fc2.weight', 'model.encoder.layers.10.fc2.bias', 'model.encoder.layers.10.final_layer_norm.weight', 'model.encoder.layers.10.final_layer_norm.bias', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.11.self_attn.k_proj.bias', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.11.self_attn_layer_norm.weight', 'model.encoder.layers.11.self_attn_layer_norm.bias', 'model.encoder.layers.11.fc1.weight', 'model.encoder.layers.11.fc1.bias', 'model.encoder.layers.11.fc2.weight', 'model.encoder.layers.11.fc2.bias', 'model.encoder.layers.11.final_layer_norm.weight', 'model.encoder.layers.11.final_layer_norm.bias', 'model.encoder.layers.12.self_attn.k_proj.weight', 'model.encoder.layers.12.self_attn.k_proj.bias', 'model.encoder.layers.12.self_attn.v_proj.weight', 'model.encoder.layers.12.self_attn.v_proj.bias', 'model.encoder.layers.12.self_attn.q_proj.weight', 'model.encoder.layers.12.self_attn.q_proj.bias', 'model.encoder.layers.12.self_attn.out_proj.weight', 'model.encoder.layers.12.self_attn.out_proj.bias', 'model.encoder.layers.12.self_attn_layer_norm.weight', 'model.encoder.layers.12.self_attn_layer_norm.bias', 'model.encoder.layers.12.fc1.weight', 'model.encoder.layers.12.fc1.bias', 'model.encoder.layers.12.fc2.weight', 'model.encoder.layers.12.fc2.bias', 'model.encoder.layers.12.final_layer_norm.weight', 'model.encoder.layers.12.final_layer_norm.bias', 'model.encoder.layers.13.self_attn.k_proj.weight', 'model.encoder.layers.13.self_attn.k_proj.bias', 'model.encoder.layers.13.self_attn.v_proj.weight', 'model.encoder.layers.13.self_attn.v_proj.bias', 'model.encoder.layers.13.self_attn.q_proj.weight', 'model.encoder.layers.13.self_attn.q_proj.bias', 'model.encoder.layers.13.self_attn.out_proj.weight', 'model.encoder.layers.13.self_attn.out_proj.bias', 'model.encoder.layers.13.self_attn_layer_norm.weight', 'model.encoder.layers.13.self_attn_layer_norm.bias', 'model.encoder.layers.13.fc1.weight', 'model.encoder.layers.13.fc1.bias', 'model.encoder.layers.13.fc2.weight', 'model.encoder.layers.13.fc2.bias', 'model.encoder.layers.13.final_layer_norm.weight', 'model.encoder.layers.13.final_layer_norm.bias', 'model.encoder.layers.14.self_attn.k_proj.weight', 'model.encoder.layers.14.self_attn.k_proj.bias', 'model.encoder.layers.14.self_attn.v_proj.weight', 'model.encoder.layers.14.self_attn.v_proj.bias', 'model.encoder.layers.14.self_attn.q_proj.weight', 'model.encoder.layers.14.self_attn.q_proj.bias', 'model.encoder.layers.14.self_attn.out_proj.weight', 'model.encoder.layers.14.self_attn.out_proj.bias', 'model.encoder.layers.14.self_attn_layer_norm.weight', 'model.encoder.layers.14.self_attn_layer_norm.bias', 'model.encoder.layers.14.fc1.weight', 'model.encoder.layers.14.fc1.bias', 'model.encoder.layers.14.fc2.weight', 'model.encoder.layers.14.fc2.bias', 'model.encoder.layers.14.final_layer_norm.weight', 'model.encoder.layers.14.final_layer_norm.bias', 'model.encoder.layers.15.self_attn.k_proj.weight', 'model.encoder.layers.15.self_attn.k_proj.bias', 'model.encoder.layers.15.self_attn.v_proj.weight', 'model.encoder.layers.15.self_attn.v_proj.bias', 'model.encoder.layers.15.self_attn.q_proj.weight', 'model.encoder.layers.15.self_attn.q_proj.bias', 'model.encoder.layers.15.self_attn.out_proj.weight', 'model.encoder.layers.15.self_attn.out_proj.bias', 'model.encoder.layers.15.self_attn_layer_norm.weight', 'model.encoder.layers.15.self_attn_layer_norm.bias', 'model.encoder.layers.15.fc1.weight', 'model.encoder.layers.15.fc1.bias', 'model.encoder.layers.15.fc2.weight', 'model.encoder.layers.15.fc2.bias', 'model.encoder.layers.15.final_layer_norm.weight', 'model.encoder.layers.15.final_layer_norm.bias', 'model.encoder.layers.16.self_attn.k_proj.weight', 'model.encoder.layers.16.self_attn.k_proj.bias', 'model.encoder.layers.16.self_attn.v_proj.weight', 'model.encoder.layers.16.self_attn.v_proj.bias', 'model.encoder.layers.16.self_attn.q_proj.weight', 'model.encoder.layers.16.self_attn.q_proj.bias', 'model.encoder.layers.16.self_attn.out_proj.weight', 'model.encoder.layers.16.self_attn.out_proj.bias', 'model.encoder.layers.16.self_attn_layer_norm.weight', 'model.encoder.layers.16.self_attn_layer_norm.bias', 'model.encoder.layers.16.fc1.weight', 'model.encoder.layers.16.fc1.bias', 'model.encoder.layers.16.fc2.weight', 'model.encoder.layers.16.fc2.bias', 'model.encoder.layers.16.final_layer_norm.weight', 'model.encoder.layers.16.final_layer_norm.bias', 'model.encoder.layers.17.self_attn.k_proj.weight', 'model.encoder.layers.17.self_attn.k_proj.bias', 'model.encoder.layers.17.self_attn.v_proj.weight', 'model.encoder.layers.17.self_attn.v_proj.bias', 'model.encoder.layers.17.self_attn.q_proj.weight', 'model.encoder.layers.17.self_attn.q_proj.bias', 'model.encoder.layers.17.self_attn.out_proj.weight', 'model.encoder.layers.17.self_attn.out_proj.bias', 'model.encoder.layers.17.self_attn_layer_norm.weight', 'model.encoder.layers.17.self_attn_layer_norm.bias', 'model.encoder.layers.17.fc1.weight', 'model.encoder.layers.17.fc1.bias', 'model.encoder.layers.17.fc2.weight', 'model.encoder.layers.17.fc2.bias', 'model.encoder.layers.17.final_layer_norm.weight', 'model.encoder.layers.17.final_layer_norm.bias', 'model.encoder.layers.18.self_attn.k_proj.weight', 'model.encoder.layers.18.self_attn.k_proj.bias', 'model.encoder.layers.18.self_attn.v_proj.weight', 'model.encoder.layers.18.self_attn.v_proj.bias', 'model.encoder.layers.18.self_attn.q_proj.weight', 'model.encoder.layers.18.self_attn.q_proj.bias', 'model.encoder.layers.18.self_attn.out_proj.weight', 'model.encoder.layers.18.self_attn.out_proj.bias', 'model.encoder.layers.18.self_attn_layer_norm.weight', 'model.encoder.layers.18.self_attn_layer_norm.bias', 'model.encoder.layers.18.fc1.weight', 'model.encoder.layers.18.fc1.bias', 'model.encoder.layers.18.fc2.weight', 'model.encoder.layers.18.fc2.bias', 'model.encoder.layers.18.final_layer_norm.weight', 'model.encoder.layers.18.final_layer_norm.bias', 'model.encoder.layers.19.self_attn.k_proj.weight', 'model.encoder.layers.19.self_attn.k_proj.bias', 'model.encoder.layers.19.self_attn.v_proj.weight', 'model.encoder.layers.19.self_attn.v_proj.bias', 'model.encoder.layers.19.self_attn.q_proj.weight', 'model.encoder.layers.19.self_attn.q_proj.bias', 'model.encoder.layers.19.self_attn.out_proj.weight', 'model.encoder.layers.19.self_attn.out_proj.bias', 'model.encoder.layers.19.self_attn_layer_norm.weight', 'model.encoder.layers.19.self_attn_layer_norm.bias', 'model.encoder.layers.19.fc1.weight', 'model.encoder.layers.19.fc1.bias', 'model.encoder.layers.19.fc2.weight', 'model.encoder.layers.19.fc2.bias', 'model.encoder.layers.19.final_layer_norm.weight', 'model.encoder.layers.19.final_layer_norm.bias', 'model.encoder.layers.20.self_attn.k_proj.weight', 'model.encoder.layers.20.self_attn.k_proj.bias', 'model.encoder.layers.20.self_attn.v_proj.weight', 'model.encoder.layers.20.self_attn.v_proj.bias', 'model.encoder.layers.20.self_attn.q_proj.weight', 'model.encoder.layers.20.self_attn.q_proj.bias', 'model.encoder.layers.20.self_attn.out_proj.weight', 'model.encoder.layers.20.self_attn.out_proj.bias', 'model.encoder.layers.20.self_attn_layer_norm.weight', 'model.encoder.layers.20.self_attn_layer_norm.bias', 'model.encoder.layers.20.fc1.weight', 'model.encoder.layers.20.fc1.bias', 'model.encoder.layers.20.fc2.weight', 'model.encoder.layers.20.fc2.bias', 'model.encoder.layers.20.final_layer_norm.weight', 'model.encoder.layers.20.final_layer_norm.bias', 'model.encoder.layers.21.self_attn.k_proj.weight', 'model.encoder.layers.21.self_attn.k_proj.bias', 'model.encoder.layers.21.self_attn.v_proj.weight', 'model.encoder.layers.21.self_attn.v_proj.bias', 'model.encoder.layers.21.self_attn.q_proj.weight', 'model.encoder.layers.21.self_attn.q_proj.bias', 'model.encoder.layers.21.self_attn.out_proj.weight', 'model.encoder.layers.21.self_attn.out_proj.bias', 'model.encoder.layers.21.self_attn_layer_norm.weight', 'model.encoder.layers.21.self_attn_layer_norm.bias', 'model.encoder.layers.21.fc1.weight', 'model.encoder.layers.21.fc1.bias', 'model.encoder.layers.21.fc2.weight', 'model.encoder.layers.21.fc2.bias', 'model.encoder.layers.21.final_layer_norm.weight', 'model.encoder.layers.21.final_layer_norm.bias', 'model.encoder.layers.22.self_attn.k_proj.weight', 'model.encoder.layers.22.self_attn.k_proj.bias', 'model.encoder.layers.22.self_attn.v_proj.weight', 'model.encoder.layers.22.self_attn.v_proj.bias', 'model.encoder.layers.22.self_attn.q_proj.weight', 'model.encoder.layers.22.self_attn.q_proj.bias', 'model.encoder.layers.22.self_attn.out_proj.weight', 'model.encoder.layers.22.self_attn.out_proj.bias', 'model.encoder.layers.22.self_attn_layer_norm.weight', 'model.encoder.layers.22.self_attn_layer_norm.bias', 'model.encoder.layers.22.fc1.weight', 'model.encoder.layers.22.fc1.bias', 'model.encoder.layers.22.fc2.weight', 'model.encoder.layers.22.fc2.bias', 'model.encoder.layers.22.final_layer_norm.weight', 'model.encoder.layers.22.final_layer_norm.bias', 'model.encoder.layers.23.self_attn.k_proj.weight', 'model.encoder.layers.23.self_attn.k_proj.bias', 'model.encoder.layers.23.self_attn.v_proj.weight', 'model.encoder.layers.23.self_attn.v_proj.bias', 'model.encoder.layers.23.self_attn.q_proj.weight', 'model.encoder.layers.23.self_attn.q_proj.bias', 'model.encoder.layers.23.self_attn.out_proj.weight', 'model.encoder.layers.23.self_attn.out_proj.bias', 'model.encoder.layers.23.self_attn_layer_norm.weight', 'model.encoder.layers.23.self_attn_layer_norm.bias', 'model.encoder.layers.23.fc1.weight', 'model.encoder.layers.23.fc1.bias', 'model.encoder.layers.23.fc2.weight', 'model.encoder.layers.23.fc2.bias', 'model.encoder.layers.23.final_layer_norm.weight', 'model.encoder.layers.23.final_layer_norm.bias', 'model.encoder.layer_norm.weight', 'model.encoder.layer_norm.bias', 'model.decoder.embed_tokens.weight', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.0.encoder_attn.k_proj.weight', 'model.decoder.layers.0.encoder_attn.k_proj.bias', 'model.decoder.layers.0.encoder_attn.v_proj.weight', 'model.decoder.layers.0.encoder_attn.v_proj.bias', 'model.decoder.layers.0.encoder_attn.q_proj.weight', 'model.decoder.layers.0.encoder_attn.q_proj.bias', 'model.decoder.layers.0.encoder_attn.out_proj.weight', 'model.decoder.layers.0.encoder_attn.out_proj.bias', 'model.decoder.layers.0.encoder_attn_layer_norm.weight', 'model.decoder.layers.0.encoder_attn_layer_norm.bias', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.1.encoder_attn.k_proj.weight', 'model.decoder.layers.1.encoder_attn.k_proj.bias', 'model.decoder.layers.1.encoder_attn.v_proj.weight', 'model.decoder.layers.1.encoder_attn.v_proj.bias', 'model.decoder.layers.1.encoder_attn.q_proj.weight', 'model.decoder.layers.1.encoder_attn.q_proj.bias', 'model.decoder.layers.1.encoder_attn.out_proj.weight', 'model.decoder.layers.1.encoder_attn.out_proj.bias', 'model.decoder.layers.1.encoder_attn_layer_norm.weight', 'model.decoder.layers.1.encoder_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.2.encoder_attn.k_proj.weight', 'model.decoder.layers.2.encoder_attn.k_proj.bias', 'model.decoder.layers.2.encoder_attn.v_proj.weight', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.decoder.layers.2.encoder_attn.q_proj.weight', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.decoder.layers.2.encoder_attn.out_proj.weight', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.decoder.layers.2.encoder_attn_layer_norm.weight', 'model.decoder.layers.2.encoder_attn_layer_norm.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.k_proj.weight', 'model.decoder.layers.3.encoder_attn.k_proj.bias', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.decoder.layers.4.encoder_attn.k_proj.bias', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.decoder.layers.4.encoder_attn.v_proj.bias', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.decoder.layers.5.encoder_attn.k_proj.bias', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.6.encoder_attn.k_proj.weight', 'model.decoder.layers.6.encoder_attn.k_proj.bias', 'model.decoder.layers.6.encoder_attn.v_proj.weight', 'model.decoder.layers.6.encoder_attn.v_proj.bias', 'model.decoder.layers.6.encoder_attn.q_proj.weight', 'model.decoder.layers.6.encoder_attn.q_proj.bias', 'model.decoder.layers.6.encoder_attn.out_proj.weight', 'model.decoder.layers.6.encoder_attn.out_proj.bias', 'model.decoder.layers.6.encoder_attn_layer_norm.weight', 'model.decoder.layers.6.encoder_attn_layer_norm.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.7.encoder_attn.k_proj.weight', 'model.decoder.layers.7.encoder_attn.k_proj.bias', 'model.decoder.layers.7.encoder_attn.v_proj.weight', 'model.decoder.layers.7.encoder_attn.v_proj.bias', 'model.decoder.layers.7.encoder_attn.q_proj.weight', 'model.decoder.layers.7.encoder_attn.q_proj.bias', 'model.decoder.layers.7.encoder_attn.out_proj.weight', 'model.decoder.layers.7.encoder_attn.out_proj.bias', 'model.decoder.layers.7.encoder_attn_layer_norm.weight', 'model.decoder.layers.7.encoder_attn_layer_norm.bias', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.8.encoder_attn.k_proj.weight', 'model.decoder.layers.8.encoder_attn.k_proj.bias', 'model.decoder.layers.8.encoder_attn.v_proj.weight', 'model.decoder.layers.8.encoder_attn.v_proj.bias', 'model.decoder.layers.8.encoder_attn.q_proj.weight', 'model.decoder.layers.8.encoder_attn.q_proj.bias', 'model.decoder.layers.8.encoder_attn.out_proj.weight', 'model.decoder.layers.8.encoder_attn.out_proj.bias', 'model.decoder.layers.8.encoder_attn_layer_norm.weight', 'model.decoder.layers.8.encoder_attn_layer_norm.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.9.encoder_attn.k_proj.weight', 'model.decoder.layers.9.encoder_attn.k_proj.bias', 'model.decoder.layers.9.encoder_attn.v_proj.weight', 'model.decoder.layers.9.encoder_attn.v_proj.bias', 'model.decoder.layers.9.encoder_attn.q_proj.weight', 'model.decoder.layers.9.encoder_attn.q_proj.bias', 'model.decoder.layers.9.encoder_attn.out_proj.weight', 'model.decoder.layers.9.encoder_attn.out_proj.bias', 'model.decoder.layers.9.encoder_attn_layer_norm.weight', 'model.decoder.layers.9.encoder_attn_layer_norm.bias', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.10.encoder_attn.k_proj.weight', 'model.decoder.layers.10.encoder_attn.k_proj.bias', 'model.decoder.layers.10.encoder_attn.v_proj.weight', 'model.decoder.layers.10.encoder_attn.v_proj.bias', 'model.decoder.layers.10.encoder_attn.q_proj.weight', 'model.decoder.layers.10.encoder_attn.q_proj.bias', 'model.decoder.layers.10.encoder_attn.out_proj.weight', 'model.decoder.layers.10.encoder_attn.out_proj.bias', 'model.decoder.layers.10.encoder_attn_layer_norm.weight', 'model.decoder.layers.10.encoder_attn_layer_norm.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.11.encoder_attn.k_proj.weight', 'model.decoder.layers.11.encoder_attn.k_proj.bias', 'model.decoder.layers.11.encoder_attn.v_proj.weight', 'model.decoder.layers.11.encoder_attn.v_proj.bias', 'model.decoder.layers.11.encoder_attn.q_proj.weight', 'model.decoder.layers.11.encoder_attn.q_proj.bias', 'model.decoder.layers.11.encoder_attn.out_proj.weight', 'model.decoder.layers.11.encoder_attn.out_proj.bias', 'model.decoder.layers.11.encoder_attn_layer_norm.weight', 'model.decoder.layers.11.encoder_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'model.decoder.layers.12.self_attn.k_proj.weight', 'model.decoder.layers.12.self_attn.k_proj.bias', 'model.decoder.layers.12.self_attn.v_proj.weight', 'model.decoder.layers.12.self_attn.v_proj.bias', 'model.decoder.layers.12.self_attn.q_proj.weight', 'model.decoder.layers.12.self_attn.q_proj.bias', 'model.decoder.layers.12.self_attn.out_proj.weight', 'model.decoder.layers.12.self_attn.out_proj.bias', 'model.decoder.layers.12.self_attn_layer_norm.weight', 'model.decoder.layers.12.self_attn_layer_norm.bias', 'model.decoder.layers.12.encoder_attn.k_proj.weight', 'model.decoder.layers.12.encoder_attn.k_proj.bias', 'model.decoder.layers.12.encoder_attn.v_proj.weight', 'model.decoder.layers.12.encoder_attn.v_proj.bias', 'model.decoder.layers.12.encoder_attn.q_proj.weight', 'model.decoder.layers.12.encoder_attn.q_proj.bias', 'model.decoder.layers.12.encoder_attn.out_proj.weight', 'model.decoder.layers.12.encoder_attn.out_proj.bias', 'model.decoder.layers.12.encoder_attn_layer_norm.weight', 'model.decoder.layers.12.encoder_attn_layer_norm.bias', 'model.decoder.layers.12.fc1.weight', 'model.decoder.layers.12.fc1.bias', 'model.decoder.layers.12.fc2.weight', 'model.decoder.layers.12.fc2.bias', 'model.decoder.layers.12.final_layer_norm.weight', 'model.decoder.layers.12.final_layer_norm.bias', 'model.decoder.layers.13.self_attn.k_proj.weight', 'model.decoder.layers.13.self_attn.k_proj.bias', 'model.decoder.layers.13.self_attn.v_proj.weight', 'model.decoder.layers.13.self_attn.v_proj.bias', 'model.decoder.layers.13.self_attn.q_proj.weight', 'model.decoder.layers.13.self_attn.q_proj.bias', 'model.decoder.layers.13.self_attn.out_proj.weight', 'model.decoder.layers.13.self_attn.out_proj.bias', 'model.decoder.layers.13.self_attn_layer_norm.weight', 'model.decoder.layers.13.self_attn_layer_norm.bias', 'model.decoder.layers.13.encoder_attn.k_proj.weight', 'model.decoder.layers.13.encoder_attn.k_proj.bias', 'model.decoder.layers.13.encoder_attn.v_proj.weight', 'model.decoder.layers.13.encoder_attn.v_proj.bias', 'model.decoder.layers.13.encoder_attn.q_proj.weight', 'model.decoder.layers.13.encoder_attn.q_proj.bias', 'model.decoder.layers.13.encoder_attn.out_proj.weight', 'model.decoder.layers.13.encoder_attn.out_proj.bias', 'model.decoder.layers.13.encoder_attn_layer_norm.weight', 'model.decoder.layers.13.encoder_attn_layer_norm.bias', 'model.decoder.layers.13.fc1.weight', 'model.decoder.layers.13.fc1.bias', 'model.decoder.layers.13.fc2.weight', 'model.decoder.layers.13.fc2.bias', 'model.decoder.layers.13.final_layer_norm.weight', 'model.decoder.layers.13.final_layer_norm.bias', 'model.decoder.layers.14.self_attn.k_proj.weight', 'model.decoder.layers.14.self_attn.k_proj.bias', 'model.decoder.layers.14.self_attn.v_proj.weight', 'model.decoder.layers.14.self_attn.v_proj.bias', 'model.decoder.layers.14.self_attn.q_proj.weight', 'model.decoder.layers.14.self_attn.q_proj.bias', 'model.decoder.layers.14.self_attn.out_proj.weight', 'model.decoder.layers.14.self_attn.out_proj.bias', 'model.decoder.layers.14.self_attn_layer_norm.weight', 'model.decoder.layers.14.self_attn_layer_norm.bias', 'model.decoder.layers.14.encoder_attn.k_proj.weight', 'model.decoder.layers.14.encoder_attn.k_proj.bias', 'model.decoder.layers.14.encoder_attn.v_proj.weight', 'model.decoder.layers.14.encoder_attn.v_proj.bias', 'model.decoder.layers.14.encoder_attn.q_proj.weight', 'model.decoder.layers.14.encoder_attn.q_proj.bias', 'model.decoder.layers.14.encoder_attn.out_proj.weight', 'model.decoder.layers.14.encoder_attn.out_proj.bias', 'model.decoder.layers.14.encoder_attn_layer_norm.weight', 'model.decoder.layers.14.encoder_attn_layer_norm.bias', 'model.decoder.layers.14.fc1.weight', 'model.decoder.layers.14.fc1.bias', 'model.decoder.layers.14.fc2.weight', 'model.decoder.layers.14.fc2.bias', 'model.decoder.layers.14.final_layer_norm.weight', 'model.decoder.layers.14.final_layer_norm.bias', 'model.decoder.layers.15.self_attn.k_proj.weight', 'model.decoder.layers.15.self_attn.k_proj.bias', 'model.decoder.layers.15.self_attn.v_proj.weight', 'model.decoder.layers.15.self_attn.v_proj.bias', 'model.decoder.layers.15.self_attn.q_proj.weight', 'model.decoder.layers.15.self_attn.q_proj.bias', 'model.decoder.layers.15.self_attn.out_proj.weight', 'model.decoder.layers.15.self_attn.out_proj.bias', 'model.decoder.layers.15.self_attn_layer_norm.weight', 'model.decoder.layers.15.self_attn_layer_norm.bias', 'model.decoder.layers.15.encoder_attn.k_proj.weight', 'model.decoder.layers.15.encoder_attn.k_proj.bias', 'model.decoder.layers.15.encoder_attn.v_proj.weight', 'model.decoder.layers.15.encoder_attn.v_proj.bias', 'model.decoder.layers.15.encoder_attn.q_proj.weight', 'model.decoder.layers.15.encoder_attn.q_proj.bias', 'model.decoder.layers.15.encoder_attn.out_proj.weight', 'model.decoder.layers.15.encoder_attn.out_proj.bias', 'model.decoder.layers.15.encoder_attn_layer_norm.weight', 'model.decoder.layers.15.encoder_attn_layer_norm.bias', 'model.decoder.layers.15.fc1.weight', 'model.decoder.layers.15.fc1.bias', 'model.decoder.layers.15.fc2.weight', 'model.decoder.layers.15.fc2.bias', 'model.decoder.layers.15.final_layer_norm.weight', 'model.decoder.layers.15.final_layer_norm.bias', 'model.decoder.layers.16.self_attn.k_proj.weight', 'model.decoder.layers.16.self_attn.k_proj.bias', 'model.decoder.layers.16.self_attn.v_proj.weight', 'model.decoder.layers.16.self_attn.v_proj.bias', 'model.decoder.layers.16.self_attn.q_proj.weight', 'model.decoder.layers.16.self_attn.q_proj.bias', 'model.decoder.layers.16.self_attn.out_proj.weight', 'model.decoder.layers.16.self_attn.out_proj.bias', 'model.decoder.layers.16.self_attn_layer_norm.weight', 'model.decoder.layers.16.self_attn_layer_norm.bias', 'model.decoder.layers.16.encoder_attn.k_proj.weight', 'model.decoder.layers.16.encoder_attn.k_proj.bias', 'model.decoder.layers.16.encoder_attn.v_proj.weight', 'model.decoder.layers.16.encoder_attn.v_proj.bias', 'model.decoder.layers.16.encoder_attn.q_proj.weight', 'model.decoder.layers.16.encoder_attn.q_proj.bias', 'model.decoder.layers.16.encoder_attn.out_proj.weight', 'model.decoder.layers.16.encoder_attn.out_proj.bias', 'model.decoder.layers.16.encoder_attn_layer_norm.weight', 'model.decoder.layers.16.encoder_attn_layer_norm.bias', 'model.decoder.layers.16.fc1.weight', 'model.decoder.layers.16.fc1.bias', 'model.decoder.layers.16.fc2.weight', 'model.decoder.layers.16.fc2.bias', 'model.decoder.layers.16.final_layer_norm.weight', 'model.decoder.layers.16.final_layer_norm.bias', 'model.decoder.layers.17.self_attn.k_proj.weight', 'model.decoder.layers.17.self_attn.k_proj.bias', 'model.decoder.layers.17.self_attn.v_proj.weight', 'model.decoder.layers.17.self_attn.v_proj.bias', 'model.decoder.layers.17.self_attn.q_proj.weight', 'model.decoder.layers.17.self_attn.q_proj.bias', 'model.decoder.layers.17.self_attn.out_proj.weight', 'model.decoder.layers.17.self_attn.out_proj.bias', 'model.decoder.layers.17.self_attn_layer_norm.weight', 'model.decoder.layers.17.self_attn_layer_norm.bias', 'model.decoder.layers.17.encoder_attn.k_proj.weight', 'model.decoder.layers.17.encoder_attn.k_proj.bias', 'model.decoder.layers.17.encoder_attn.v_proj.weight', 'model.decoder.layers.17.encoder_attn.v_proj.bias', 'model.decoder.layers.17.encoder_attn.q_proj.weight', 'model.decoder.layers.17.encoder_attn.q_proj.bias', 'model.decoder.layers.17.encoder_attn.out_proj.weight', 'model.decoder.layers.17.encoder_attn.out_proj.bias', 'model.decoder.layers.17.encoder_attn_layer_norm.weight', 'model.decoder.layers.17.encoder_attn_layer_norm.bias', 'model.decoder.layers.17.fc1.weight', 'model.decoder.layers.17.fc1.bias', 'model.decoder.layers.17.fc2.weight', 'model.decoder.layers.17.fc2.bias', 'model.decoder.layers.17.final_layer_norm.weight', 'model.decoder.layers.17.final_layer_norm.bias', 'model.decoder.layers.18.self_attn.k_proj.weight', 'model.decoder.layers.18.self_attn.k_proj.bias', 'model.decoder.layers.18.self_attn.v_proj.weight', 'model.decoder.layers.18.self_attn.v_proj.bias', 'model.decoder.layers.18.self_attn.q_proj.weight', 'model.decoder.layers.18.self_attn.q_proj.bias', 'model.decoder.layers.18.self_attn.out_proj.weight', 'model.decoder.layers.18.self_attn.out_proj.bias', 'model.decoder.layers.18.self_attn_layer_norm.weight', 'model.decoder.layers.18.self_attn_layer_norm.bias', 'model.decoder.layers.18.encoder_attn.k_proj.weight', 'model.decoder.layers.18.encoder_attn.k_proj.bias', 'model.decoder.layers.18.encoder_attn.v_proj.weight', 'model.decoder.layers.18.encoder_attn.v_proj.bias', 'model.decoder.layers.18.encoder_attn.q_proj.weight', 'model.decoder.layers.18.encoder_attn.q_proj.bias', 'model.decoder.layers.18.encoder_attn.out_proj.weight', 'model.decoder.layers.18.encoder_attn.out_proj.bias', 'model.decoder.layers.18.encoder_attn_layer_norm.weight', 'model.decoder.layers.18.encoder_attn_layer_norm.bias', 'model.decoder.layers.18.fc1.weight', 'model.decoder.layers.18.fc1.bias', 'model.decoder.layers.18.fc2.weight', 'model.decoder.layers.18.fc2.bias', 'model.decoder.layers.18.final_layer_norm.weight', 'model.decoder.layers.18.final_layer_norm.bias', 'model.decoder.layers.19.self_attn.k_proj.weight', 'model.decoder.layers.19.self_attn.k_proj.bias', 'model.decoder.layers.19.self_attn.v_proj.weight', 'model.decoder.layers.19.self_attn.v_proj.bias', 'model.decoder.layers.19.self_attn.q_proj.weight', 'model.decoder.layers.19.self_attn.q_proj.bias', 'model.decoder.layers.19.self_attn.out_proj.weight', 'model.decoder.layers.19.self_attn.out_proj.bias', 'model.decoder.layers.19.self_attn_layer_norm.weight', 'model.decoder.layers.19.self_attn_layer_norm.bias', 'model.decoder.layers.19.encoder_attn.k_proj.weight', 'model.decoder.layers.19.encoder_attn.k_proj.bias', 'model.decoder.layers.19.encoder_attn.v_proj.weight', 'model.decoder.layers.19.encoder_attn.v_proj.bias', 'model.decoder.layers.19.encoder_attn.q_proj.weight', 'model.decoder.layers.19.encoder_attn.q_proj.bias', 'model.decoder.layers.19.encoder_attn.out_proj.weight', 'model.decoder.layers.19.encoder_attn.out_proj.bias', 'model.decoder.layers.19.encoder_attn_layer_norm.weight', 'model.decoder.layers.19.encoder_attn_layer_norm.bias', 'model.decoder.layers.19.fc1.weight', 'model.decoder.layers.19.fc1.bias', 'model.decoder.layers.19.fc2.weight', 'model.decoder.layers.19.fc2.bias', 'model.decoder.layers.19.final_layer_norm.weight', 'model.decoder.layers.19.final_layer_norm.bias', 'model.decoder.layers.20.self_attn.k_proj.weight', 'model.decoder.layers.20.self_attn.k_proj.bias', 'model.decoder.layers.20.self_attn.v_proj.weight', 'model.decoder.layers.20.self_attn.v_proj.bias', 'model.decoder.layers.20.self_attn.q_proj.weight', 'model.decoder.layers.20.self_attn.q_proj.bias', 'model.decoder.layers.20.self_attn.out_proj.weight', 'model.decoder.layers.20.self_attn.out_proj.bias', 'model.decoder.layers.20.self_attn_layer_norm.weight', 'model.decoder.layers.20.self_attn_layer_norm.bias', 'model.decoder.layers.20.encoder_attn.k_proj.weight', 'model.decoder.layers.20.encoder_attn.k_proj.bias', 'model.decoder.layers.20.encoder_attn.v_proj.weight', 'model.decoder.layers.20.encoder_attn.v_proj.bias', 'model.decoder.layers.20.encoder_attn.q_proj.weight', 'model.decoder.layers.20.encoder_attn.q_proj.bias', 'model.decoder.layers.20.encoder_attn.out_proj.weight', 'model.decoder.layers.20.encoder_attn.out_proj.bias', 'model.decoder.layers.20.encoder_attn_layer_norm.weight', 'model.decoder.layers.20.encoder_attn_layer_norm.bias', 'model.decoder.layers.20.fc1.weight', 'model.decoder.layers.20.fc1.bias', 'model.decoder.layers.20.fc2.weight', 'model.decoder.layers.20.fc2.bias', 'model.decoder.layers.20.final_layer_norm.weight', 'model.decoder.layers.20.final_layer_norm.bias', 'model.decoder.layers.21.self_attn.k_proj.weight', 'model.decoder.layers.21.self_attn.k_proj.bias', 'model.decoder.layers.21.self_attn.v_proj.weight', 'model.decoder.layers.21.self_attn.v_proj.bias', 'model.decoder.layers.21.self_attn.q_proj.weight', 'model.decoder.layers.21.self_attn.q_proj.bias', 'model.decoder.layers.21.self_attn.out_proj.weight', 'model.decoder.layers.21.self_attn.out_proj.bias', 'model.decoder.layers.21.self_attn_layer_norm.weight', 'model.decoder.layers.21.self_attn_layer_norm.bias', 'model.decoder.layers.21.encoder_attn.k_proj.weight', 'model.decoder.layers.21.encoder_attn.k_proj.bias', 'model.decoder.layers.21.encoder_attn.v_proj.weight', 'model.decoder.layers.21.encoder_attn.v_proj.bias', 'model.decoder.layers.21.encoder_attn.q_proj.weight', 'model.decoder.layers.21.encoder_attn.q_proj.bias', 'model.decoder.layers.21.encoder_attn.out_proj.weight', 'model.decoder.layers.21.encoder_attn.out_proj.bias', 'model.decoder.layers.21.encoder_attn_layer_norm.weight', 'model.decoder.layers.21.encoder_attn_layer_norm.bias', 'model.decoder.layers.21.fc1.weight', 'model.decoder.layers.21.fc1.bias', 'model.decoder.layers.21.fc2.weight', 'model.decoder.layers.21.fc2.bias', 'model.decoder.layers.21.final_layer_norm.weight', 'model.decoder.layers.21.final_layer_norm.bias', 'model.decoder.layers.22.self_attn.k_proj.weight', 'model.decoder.layers.22.self_attn.k_proj.bias', 'model.decoder.layers.22.self_attn.v_proj.weight', 'model.decoder.layers.22.self_attn.v_proj.bias', 'model.decoder.layers.22.self_attn.q_proj.weight', 'model.decoder.layers.22.self_attn.q_proj.bias', 'model.decoder.layers.22.self_attn.out_proj.weight', 'model.decoder.layers.22.self_attn.out_proj.bias', 'model.decoder.layers.22.self_attn_layer_norm.weight', 'model.decoder.layers.22.self_attn_layer_norm.bias', 'model.decoder.layers.22.encoder_attn.k_proj.weight', 'model.decoder.layers.22.encoder_attn.k_proj.bias', 'model.decoder.layers.22.encoder_attn.v_proj.weight', 'model.decoder.layers.22.encoder_attn.v_proj.bias', 'model.decoder.layers.22.encoder_attn.q_proj.weight', 'model.decoder.layers.22.encoder_attn.q_proj.bias', 'model.decoder.layers.22.encoder_attn.out_proj.weight', 'model.decoder.layers.22.encoder_attn.out_proj.bias', 'model.decoder.layers.22.encoder_attn_layer_norm.weight', 'model.decoder.layers.22.encoder_attn_layer_norm.bias', 'model.decoder.layers.22.fc1.weight', 'model.decoder.layers.22.fc1.bias', 'model.decoder.layers.22.fc2.weight', 'model.decoder.layers.22.fc2.bias', 'model.decoder.layers.22.final_layer_norm.weight', 'model.decoder.layers.22.final_layer_norm.bias', 'model.decoder.layers.23.self_attn.k_proj.weight', 'model.decoder.layers.23.self_attn.k_proj.bias', 'model.decoder.layers.23.self_attn.v_proj.weight', 'model.decoder.layers.23.self_attn.v_proj.bias', 'model.decoder.layers.23.self_attn.q_proj.weight', 'model.decoder.layers.23.self_attn.q_proj.bias', 'model.decoder.layers.23.self_attn.out_proj.weight', 'model.decoder.layers.23.self_attn.out_proj.bias', 'model.decoder.layers.23.self_attn_layer_norm.weight', 'model.decoder.layers.23.self_attn_layer_norm.bias', 'model.decoder.layers.23.encoder_attn.k_proj.weight', 'model.decoder.layers.23.encoder_attn.k_proj.bias', 'model.decoder.layers.23.encoder_attn.v_proj.weight', 'model.decoder.layers.23.encoder_attn.v_proj.bias', 'model.decoder.layers.23.encoder_attn.q_proj.weight', 'model.decoder.layers.23.encoder_attn.q_proj.bias', 'model.decoder.layers.23.encoder_attn.out_proj.weight', 'model.decoder.layers.23.encoder_attn.out_proj.bias', 'model.decoder.layers.23.encoder_attn_layer_norm.weight', 'model.decoder.layers.23.encoder_attn_layer_norm.bias', 'model.decoder.layers.23.fc1.weight', 'model.decoder.layers.23.fc1.bias', 'model.decoder.layers.23.fc2.weight', 'model.decoder.layers.23.fc2.bias', 'model.decoder.layers.23.final_layer_norm.weight', 'model.decoder.layers.23.final_layer_norm.bias', 'model.decoder.layer_norm.weight', 'model.decoder.layer_norm.bias', 'lm_head.weight']
   (Ï≤òÏùå 10Í∞úÎßå ÌëúÏãú)
     - model.shared.weight: <class 'torch.Tensor'> torch.Size([256206, 1024])
     - model.encoder.embed_tokens.weight: <class 'torch.Tensor'> torch.Size([256206, 1024])
     - model.encoder.layers.0.self_attn.k_proj.weight: <class 'torch.Tensor'> torch.Size([1024, 1024])
     - model.encoder.layers.0.self_attn.k_proj.bias: <class 'torch.Tensor'> torch.Size([1024])
     - model.encoder.layers.0.self_attn.v_proj.weight: <class 'torch.Tensor'> torch.Size([1024, 1024])
     - model.encoder.layers.0.self_attn.v_proj.bias: <class 'torch.Tensor'> torch.Size([1024])
     - model.encoder.layers.0.self_attn.q_proj.weight: <class 'torch.Tensor'> torch.Size([1024, 1024])
     - model.encoder.layers.0.self_attn.q_proj.bias: <class 'torch.Tensor'> torch.Size([1024])
     - model.encoder.layers.0.self_attn.out_proj.weight: <class 'torch.Tensor'> torch.Size([1024, 1024])
     - model.encoder.layers.0.self_attn.out_proj.bias: <class 'torch.Tensor'> torch.Size([1024])

üîë ÌÇ§: config
   ÌÉÄÏûÖ: <class 'transformers.models.m2m_100.configuration_m2m_100.M2M100Config'>
   Í∞í: M2M100Config {
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "architectures": [
  ...

üîë ÌÇ§: tokenizer
   ÌÉÄÏûÖ: <class 'transformers.models.nllb.tokenization_nllb_fast.NllbTokenizerFast'>
   Í∏∏Ïù¥: 256204

üîë ÌÇ§: model_info
   ÌÉÄÏûÖ: <class 'dict'>
   ÌïòÏúÑ ÌÇ§Îì§: ['model_type', 'finetuned', 'tsel_thinking', 'korean_complexity', 'h100_optimized', 'dataset_size', 'training_epochs', 'optimization_level']

============================================================
üîß Î™®Îç∏ ÏÉÅÌÉú ÎîïÏÖîÎÑàÎ¶¨ Î∂ÑÏÑù
============================================================
üìä Î™®Îç∏ ÏÉÅÌÉú ÎîïÏÖîÎÑàÎ¶¨ ÌÇ§ Í∞úÏàò: 1016

üèóÔ∏è  Ï£ºÏöî Î†àÏù¥Ïñ¥Îì§:
   model: 1015Í∞ú ÌååÎùºÎØ∏ÌÑ∞
     - model.shared.weight: torch.Size([256206, 1024])
     - model.encoder.embed_tokens.weight: torch.Size([256206, 1024])
     - model.encoder.layers.0.self_attn.k_proj.weight: torch.Size([1024, 1024])
     ... (Ï¥ù 1015Í∞ú)
   lm_head: 1Í∞ú ÌååÎùºÎØ∏ÌÑ∞
     - lm_head.weight: torch.Size([256206, 1024])

============================================================
üéØ ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Ï†ïÎ≥¥
============================================================
üìù ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä ÌÉÄÏûÖ: <class 'transformers.models.nllb.tokenization_nllb_fast.NllbTokenizerFast'>
üìä Ïñ¥Ìúò ÌÅ¨Í∏∞: 256204
üî§ ÌäπÏàò ÌÜ†ÌÅ∞Îì§:
   - PAD: 1
   - BOS: 0
   - EOS: 2
   - UNK: 3

============================================================
‚öôÔ∏è ÏÑ§Ï†ï Ï†ïÎ≥¥
============================================================
üìã ÏÑ§Ï†ï ÌÉÄÏûÖ: <class 'transformers.models.m2m_100.configuration_m2m_100.M2M100Config'>
   vocab_size: 256206
   max_position_embeddings: 1024
   d_model: 1024
   encoder_ffn_dim: 8192
   encoder_layers: 24
   encoder_attention_heads: 16
   decoder_ffn_dim: 8192
   decoder_layers: 24
   decoder_attention_heads: 16
   dropout: 0.1
   attention_dropout: 0.1
   activation_dropout: 0.0
   activation_function: relu
   init_std: 0.02
   encoder_layerdrop: 0
   decoder_layerdrop: 0
   use_cache: False
   num_hidden_layers: 24
   scale_embedding: True
   return_dict: True
   output_hidden_states: False
   output_attentions: False
   torchscript: False
   torch_dtype: float32
   use_bfloat16: False
   tf_legacy_loss: False
   pruned_heads: {}
   tie_word_embeddings: True
   chunk_size_feed_forward: 0
   is_encoder_decoder: True
   is_decoder: False
   cross_attention_hidden_size: None
   add_cross_attention: False
   tie_encoder_decoder: False
   max_length: None
   min_length: 0
   do_sample: False
   early_stopping: False
   num_beams: 1
   num_beam_groups: 1
   diversity_penalty: 0.0
   temperature: 1.0
   top_k: 50
   top_p: 1.0
   typical_p: 1.0
   repetition_penalty: 1.0
   length_penalty: 1.0
   no_repeat_ngram_size: 0
   encoder_no_repeat_ngram_size: 0
   bad_words_ids: None
   num_return_sequences: 1
   output_scores: False
   return_dict_in_generate: False
   forced_bos_token_id: None
   forced_eos_token_id: None
   remove_invalid_values: False
   exponential_decay_length_penalty: None
   suppress_tokens: None
   begin_suppress_tokens: None
   architectures: ['M2M100ForConditionalGeneration']
   finetuning_task: None
   id2label: {0: 'LABEL_0', 1: 'LABEL_1'}
   label2id: {'LABEL_0': 0, 'LABEL_1': 1}
   tokenizer_class: None
   prefix: None
   bos_token_id: 0
   pad_token_id: 1
   eos_token_id: 2
   sep_token_id: None
   decoder_start_token_id: 2
   task_specific_params: None
   problem_type: None
   transformers_version: 4.21.0.dev0
   model_type: m2m_100
   gradient_checkpointing: True

============================================================
üíæ ÌååÏùº ÌÅ¨Í∏∞ Ï†ïÎ≥¥
============================================================
üìÅ ÌååÏùº ÌÅ¨Í∏∞: 5246.3MB
üî¢ Ï¥ù ÌååÎùºÎØ∏ÌÑ∞ Ïàò: 2,157,703,168

‚úÖ Î∂ÑÏÑù ÏôÑÎ£å!